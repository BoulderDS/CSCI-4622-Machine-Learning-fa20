{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "dce7f1acc2109a9c9edc64e7113f2a91",
     "grade": false,
     "grade_id": "cell-fad434183ac9d38e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Homework 5: Boosting and PCA\n",
    "\n",
    "\n",
    "This assignment is due on Canvas by **11:59pm on Sunday November 15**. \n",
    "Your solutions to theoretical questions should be done in Markdown/MathJax directly below the associated question.\n",
    "Your solutions to computational questions should include any specified Python code and results \n",
    "as well as written commentary on your conclusions.\n",
    "Remember that you are encouraged to discuss the problems with your instructors and classmates, \n",
    "but **you must write all code and solutions on your own**. For a refresher on the course **Collaboration Policy** click [here](https://github.com/BoulderDS/CSCI5622-Machine-Learning/blob/master/info/syllabus.md#collaboration-policy).\n",
    "\n",
    "**NOTES**: \n",
    "\n",
    "- Do **NOT** load or use any Python packages that are not available in Anaconda (Version: 2019.07) with Python 3.7. \n",
    "- Some problems with code may be autograded.  If we provide a function API **do not** change it.  If we do not provide a function API then you're free to structure your code however you like. \n",
    "- Submit only this Jupyter notebook to Moodle.  Do not compress it using tar, rar, zip, etc.\n",
    "- **Unzip the files in data folder**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e4b1cbfe47062e0199c10e23c8d48d5",
     "grade": false,
     "grade_id": "cell-58a1ea67624fe73e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Please put your name and cuidentity username.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Identity Key**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pandas\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random state for all sklearn functions\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "22cca2e69bfd0abb58373837658269c7",
     "grade": false,
     "grade_id": "cell-e0a66a81cc5eb433",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[40 points] Problem 1 - Principal Component Analysis\n",
    "---\n",
    "\n",
    "In this problem you'll be implementing Dimensionality reduction using Principal Component Analysis technique. \n",
    "\n",
    "The gist of PCA Algorithm to compute principal components is follows:\n",
    "- Calculate the covariance matrix X of data points.\n",
    "- Calculate eigenvectors and corresponding eigenvalues.\n",
    "- Sort the eigenvectors according to their eigenvalues in decreasing order.\n",
    "- Choose first k eigenvectors which satisfies target explained variance.\n",
    "- Transform the original n dimensional data points into k dimensions.\n",
    "\n",
    "The skeleton for the `PCA` class is below. Scroll down to find more information about your tasks as well as unit tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c267a4e46bd0ae9f5477b591a9fdd33c",
     "grade": false,
     "grade_id": "cell-34ffc5741eeb12ad",
     "locked": false,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    def __init__(self, target_explained_variance=None):\n",
    "        \"\"\"\n",
    "        explained_variance: float, the target level of explained variance\n",
    "        \"\"\"\n",
    "        self.target_explained_variance = target_explained_variance\n",
    "        self.feature_size = -1\n",
    "\n",
    "    def standardize(self, X):\n",
    "        \"\"\"\n",
    "        standardize features using standard scaler\n",
    "        :param m X n: features data\n",
    "        :return: standardized features\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_mean_vector(self, X_std):\n",
    "        \"\"\"\n",
    "        compute mean vector\n",
    "        :param X_std: data\n",
    "        :return n X 1 matrix: mean vector\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_cov(self, X_std, mean_vec):\n",
    "        \"\"\"\n",
    "        Covariance using mean, (don't use any numpy.cov)\n",
    "        :param X_std:\n",
    "        :param mean_vec:\n",
    "        :return n X n matrix:: covariance matrix\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_eigen_vector(self, cov_mat):\n",
    "        \"\"\"\n",
    "        Eigenvector and eigen values using numpy\n",
    "        :param cov_mat:\n",
    "        :return: (eigen_vector,eigen_values)\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def compute_explained_variance(self, eigen_vals):\n",
    "        \"\"\"\n",
    "        sort eigen values and compute explained variance.\n",
    "        explained variance informs the amount of information (variance)\n",
    "        can be attributed to each of  the principal components.\n",
    "        :param eigen_vals:\n",
    "        :return: explained variance.\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def cumulative_sum(self, var_exp):\n",
    "        \"\"\"\n",
    "        return cumulative sum of explained variance.\n",
    "        :param var_exp: explained variance\n",
    "        :return: cumulative explained variance\n",
    "        \"\"\"\n",
    "        return np.cumsum(var_exp)\n",
    "\n",
    "    def compute_weight_matrix(self, eig_pairs, var_exp):\n",
    "        \"\"\"\n",
    "        compute weight matrix of top principal components conditioned on target\n",
    "        explained variance.\n",
    "        Hint : \n",
    "            use cumulative explained variance and target_explained_variance \n",
    "            to find top components\n",
    "        \n",
    "        :param eig_pairs: list of tuples containing eigenvector and eigen values\n",
    "        :param var_exp: *sorted* explained variance proportions, by features\n",
    "        :return: weight matrix\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "\n",
    "    def transform_data(self, X_std, matrix_w):\n",
    "        \"\"\"\n",
    "        transform data to subspace using weight matrix\n",
    "        :param X_std: standardized data\n",
    "        :param matrix_w: weight matrix\n",
    "        :return: data in the subspace\n",
    "        \"\"\"\n",
    "        return X_std.dot(matrix_w)\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        entry point to the transform data to k dimensions\n",
    "        standardize and compute weight matrix to transform data.\n",
    "        :param   m X n dimension: train samples\n",
    "        :return  m X k dimension: subspace data.\n",
    "        \"\"\"\n",
    "    \n",
    "        self.feature_size = X.shape[1]\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        return self.transform_data(X_std=X_std, matrix_w=matrix_w)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1f2038dfd79507d4f540c1c45f8346e5",
     "grade": false,
     "grade_id": "cell-f115fedc1c3aac43",
     "locked": true,
     "schema_version": 3,
     "solution": false
    }
   },
   "source": [
    "### Part 1 [20 points]\n",
    "Your task involves implementing helper functions to compute mean, \n",
    "covariance, eigenvector and weights.\n",
    "\n",
    "Complete `fit` to use all helper functions to find reduced dimension data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "11ba3527363fb8065febc0871d978739",
     "grade": true,
     "grade_id": "cell-1395ce0d605dc74a",
     "locked": true,
     "points": 20,
     "schema_version": 3,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from tests import tests\n",
    "tests.run_test_suite(\"prob 1\", PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6e41ceca31f22cf865e540951b33dcc8",
     "grade": false,
     "grade_id": "cell-8522f55858412018",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2 [5 points] Run PCA on fashion mnist dataset to reduce the dimension of the data.\n",
    "\n",
    "fashion mnist data consists of samples with 784 dimensions.\n",
    "\n",
    "Report the reduced dimension $k$ for target explained variance of **0.99**\n",
    "\n",
    "**Note: You need to unzip the data used below (you might need to install some packages)**\n",
    "\n",
    "We've added a command to perform this operation directly from the notebook, but note you're milage here may vary. If it doesn't work, you might need to install some packages for your OS accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the data\n",
    "!tar -xvf data/fashion-mnist.tar.bz2 -C data\n",
    "\n",
    "# now you can load the data\n",
    "X_train = pickle.load(open('./data/mnist/train_images.pkl','rb'))\n",
    "y_train = pickle.load(open('./data/mnist/train_image_labels.pkl','rb'))\n",
    "X_train = X_train[:15000]\n",
    "y_train = y_train[:15000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b15912907fa9d00f82d5c8e82581047b",
     "grade": true,
     "grade_id": "cell-4f2deef7b2ad8f4c",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "30b90e110f8eaddacff7c77493ec563d",
     "grade": false,
     "grade_id": "cell-44f79a0ad68133b2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3 [5 points]\n",
    "Run scikit-learn SVM Classifier (refer to previous homework) on the reduced dimension data with approrpiate kernel and C.\n",
    "\n",
    "Report the accuracy on test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_t, X_test, y_t, y_test = train_test_split(\n",
    "    X_train_updated, y_train, test_size=0.2, random_state = 5622)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1e3c0aee9c27884fa3370d9620b8d50",
     "grade": true,
     "grade_id": "cell-55ac4663a6d818e1",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fe429182996efa1da274f1c9c35140fb",
     "grade": false,
     "grade_id": "cell-f13ef14f15d0899c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 4 [10 points]\n",
    "Repeat the same experiment for different values of target explained variance between: **[0.8-1.0]** with increments of $0.04$, provide the reduced dimension size for each, and then:\n",
    "\n",
    "- Plot the graph of accuracy vs target explained variance.\n",
    "- Plot the graph of the number of components vs target explained variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9f6f3adb10a595456ca640dc021ece36",
     "grade": true,
     "grade_id": "cell-d1c639ba61115892",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# In the following lists, store for each experiment:\n",
    "#    target variance, number of components, accuracy\n",
    "# These are to be used in plotting next\n",
    "target_explained_variances = []\n",
    "numbers_of_components = []\n",
    "accuracies = []\n",
    "for target_variance in np.arange(0.8, 1.0, .04):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "384791d90ebfef520227aebf07572b05",
     "grade": true,
     "grade_id": "cell-b3d84112a8c56eb5",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Make plots here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4d247d7429692d24212353620dbb5e0",
     "grade": false,
     "grade_id": "cell-58d1fb19452dbe11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Discuss your observations below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5c7448f6358015c021d7af0aeb552751",
     "grade": true,
     "grade_id": "cell-ddf4e4516af2b2f2",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "23d07798e9afa6b28c8fc868fb22fd4b",
     "grade": false,
     "grade_id": "cell-7b01255a9362a73f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[20 points] Problem 2 - Statistical PCA for non-zero mean random variables. \n",
    "---\n",
    "Let $x \\in R^D$ be a random vector. Let $\\mu_x$ = $E(x)$  $ \\in R^D$ and $\\sum_x = E(x − \\mu)(x − \\mu)$ be mean an covariance of x respectivley. \n",
    "\n",
    "We define *Principal components* of $x$ as $v_i$. Assuming that the eigenvalues of $\\sum_x$ are different from each other\n",
    "\n",
    "show that\n",
    "\n",
    "1) $v_1$ is the eigenvector of $\\sum_x$ corresponding to its largest eigenvalue.\n",
    "\n",
    "2) $v_2^T v_1$ = 0 and $v_2$ is the eigenvector of $\\sum_x$ corresponding to its second largest eigenvalue."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5964545d9ca55b8027aacfc1d212e96a",
     "grade": true,
     "grade_id": "cell-35f08a8505587ec1",
     "locked": false,
     "points": 20,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2790e0ac5003a9ec18b0bd61a97ee7b0",
     "grade": false,
     "grade_id": "cell-39579c968d60c975",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "[40 points] Problem 3  - Decision Tree Ensembles: Bagging and Boosting\n",
    "---\n",
    "\n",
    "We are going to predict house price using decision tree ensembles.\n",
    "\n",
    "In this Regression problem, we compare Decision trees and it's ensembles - bagging and Boosting on House Price prediction dataset : https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
    "\n",
    "Make use standard Regression API's of  Decision tree ensembles from sklearn to predict the house price. http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n",
    "\n",
    "### Part 1 [20 points]\n",
    "Complete the `EnsembleTest` class to fit appropriate model recieved as parameter and store the test accuracy. This class allows us to aggregate results from multiple experiments of the same type (Regression or Classification) and report results for easier comparison.\n",
    "\n",
    "Later we will use `EnsembleTest` class to plot score, metric and time taken to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3501e3c5f84f491a167e82c8dc678a0e",
     "grade": false,
     "grade_id": "cell-2f5b11c37751fad9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.metrics import explained_variance_score, precision_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class EnsembleTest:\n",
    "    \"\"\" Test multiple model performance \"\"\"\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test, _type='regression'):\n",
    "        \"\"\"\n",
    "        initialize data and type of problem\n",
    "        :param X_train:\n",
    "        :param y_train:\n",
    "        :param X_test:\n",
    "        :param y_test:\n",
    "        :param _type: regression or classification\n",
    "        \"\"\"\n",
    "        self.scores = {}\n",
    "        self.execution_time = {}\n",
    "        self.metric = {}\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        self.type = _type\n",
    "        if _type == 'regression':\n",
    "            self.score_name = 'R^2 score' \n",
    "            self.metric_name = 'Explained variance' \n",
    "        else:\n",
    "            self.score_name = 'Mean accuracy score'\n",
    "            self.metric_name = 'Precision'\n",
    "            \n",
    "    def fit_model(self, model, name):\n",
    "        \"\"\"\n",
    "        TODO:\n",
    "        - Fit the model on train data.\n",
    "        - Store execution time required to fit.\n",
    "        - Store scores on test data\n",
    "        - Predict on test data\n",
    "        \n",
    "        Each model passed as parameter has member functions of the following form:\n",
    "          model.fit(x_train, y_train)\n",
    "          model.score(x_test, y_test) \n",
    "          model.predict(x_test)\n",
    "        \n",
    "        :param model: model\n",
    "        :param name: name of model\n",
    "        \"\"\"\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "        if self.type == 'regression':\n",
    "            self.metric[name] = explained_variance_score(self.y_test, predict)\n",
    "        elif self.type == 'classification':\n",
    "            self.metric[name] = precision_score(self.y_test, predict)\n",
    "\n",
    "    def print_result(self):\n",
    "        \"\"\"\n",
    "            print results for all models trained and tested.\n",
    "        \"\"\"\n",
    "        models_cross = pd.DataFrame({\n",
    "            'Model'         : list(self.metric.keys()),\n",
    "             self.score_name     : list(self.scores.values()),\n",
    "             self.metric_name    : list(self.metric.values()),\n",
    "            'Execution time': list(self.execution_time.values())})\n",
    "        print(models_cross.sort_values(by=self.score_name, ascending=False))\n",
    "\n",
    "    def plot_metric(self):\n",
    "        \"\"\"\n",
    "         There are 3 metrics for each type of experiment: \n",
    "             time, metric score, scores\n",
    "         Produce a bar graph for each of the above metrics\n",
    "         Each bar graph should have results from all experiments \n",
    "             of the same type side by side\n",
    "         \n",
    "         Note: The Metric name and score name depend on the type of experiment \n",
    "             (regression or classification) \n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3f625f08631ca1825113a2241e4f2ef2",
     "grade": false,
     "grade_id": "cell-fe01ff5f70024501",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Note: You need to unzip the data used below (you might need to install some packages)**\n",
    "\n",
    "As before, we've added a command to perform this operation directly from the notebook. If it doesn't work, you might need to install some packages for your OS accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip the data\n",
    "!unzip -o ./data/house_predictions.zip -d data\n",
    "# load data\n",
    "X_train, X_test, y_train, y_test = pickle.load(\n",
    "    open('./data/house_predictions/test_train.pkl','rb'))\n",
    "\n",
    "# create a handler for ensemble_test, \n",
    "# use the created handler for fitting different models.\n",
    "ensemble_handler = EnsembleTest(\n",
    "    X_train, y_train, X_test, y_test, _type='regression')\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "decision = DecisionTreeRegressor(random_state=0)\n",
    "ensemble_handler.fit_model(decision, 'decision_tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a10686476a3368315153b6bd1618878e",
     "grade": false,
     "grade_id": "cell-23fa06ea444dace7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part 1 A [10 points]\n",
    "Complete the cells below to fit the dataset using `RandomForestRegressor` and `AdaBoostRegressor` with appropriate parameter. Use `n_estimators=1000` for both regressor.\n",
    "\n",
    "**You do NOT need to create a new EnsembleTest object**\n",
    "\n",
    "EnsembleTest objects are meant to hold info from multiple experiments together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45d3a90b9307b4c71a691414ea6a5452",
     "grade": true,
     "grade_id": "cell-8a8faea9792d3de2",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f667d8b508e624228f903db96928624e",
     "grade": true,
     "grade_id": "cell-77fc8d76bfc77a0f",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "72de994f77876e46316ed64e43989758",
     "grade": false,
     "grade_id": "cell-5ab2d265d360e288",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part 1 B [5 points] Report results and make plots for the above experiments. \n",
    "\n",
    "This should take one line each (one function call each on ensemble_handler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8de42fcf797783cc942f9289ee054777",
     "grade": true,
     "grade_id": "cell-ecde0a3f23089aaf",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Report results here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bbf7cb9c1a769ac7653efe66a138cd47",
     "grade": true,
     "grade_id": "cell-2fc10988e851c39e",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Make plots here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fa4bb40cfeedcd4eecaa22d0b763679a",
     "grade": false,
     "grade_id": "cell-49cfee5739c604f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 2 [15 points] \n",
    "This is an extension of HW4 problem on sentiment classification over reviews.\n",
    "\n",
    "Here we make use DecisionTree ensembles to **classify** review as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews  = pd.read_csv('./data/reviews.csv')\n",
    "train, test = train_test_split(reviews, test_size=0.2, random_state=4622)\n",
    "X_train = train['reviews'].values\n",
    "X_test = test['reviews'].values\n",
    "y_train = train['sentiment']\n",
    "y_test = test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3306bda9688cfee15bf35aaf05363621",
     "grade": false,
     "grade_id": "cell-280d03f370cd2d31",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part 2 A [10 points]\n",
    "Perform the following: \n",
    "\n",
    "* Create pipeline for `RandomForestClassifier` and `AdaBoostClassifier` as shown for `DecisionTreeClassifier` below. Refer to: http://scikit-learn.org/stable/modules/classes.html#module-sklearn.ensemble\n",
    "* Fit the reviews dataset on the above models and report the results. (tune parameters of classifier for optimal performance)\n",
    "* Use `n_estimators = 500` for both classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Define tokenizer.\n",
    "def tokenize(text): \n",
    "    tknzr = TweetTokenizer()\n",
    "    return tknzr.tokenize(text)\n",
    "\n",
    "# vectorizer \n",
    "en_stopwords = set(stopwords.words(\"english\")) \n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer='word',\n",
    "    tokenizer=tokenize,\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 2),\n",
    "    stop_words=en_stopwords,\n",
    "    min_df=10)\n",
    "\n",
    "\n",
    "# create a handler for ensemble_test , \n",
    "# use the created handler for fitting different models.\n",
    "ensemble_classifier_handler = EnsembleTest(\n",
    "    X_train, y_train, X_test, y_test, _type='classification')\n",
    "\n",
    "\n",
    "# Create a and fit pipeline for DecisionTreeClassifier.\n",
    "pipeline_decision_tree = make_pipeline(\n",
    "    vectorizer, DecisionTreeClassifier(random_state=0))\n",
    "ensemble_classifier_handler.fit_model(\n",
    "    pipeline_decision_tree,' decision tree classifier')\n",
    "ensemble_classifier_handler.print_result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2896029d78697bc6a8705bdadb8f85a5",
     "grade": true,
     "grade_id": "cell-5ba823d25c616289",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# TODO: Create a and fit pipeline for RandomForestClassifier.\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "222b3470c1a8ebe4104758cf31952026",
     "grade": true,
     "grade_id": "cell-0921e901522a923e",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# TODO: Create a and fit pipeline for AdaBoostClassifier\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "6d0c1b898cbd69697bbd98a5e8a8eb69",
     "grade": false,
     "grade_id": "cell-68b2f7a21cedfef3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "#### Part 2 B [5 points] Report results and make plots.\n",
    "\n",
    "This should take one line each (one function call each on ensemble_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f0b991c14cb2d605bac8f5fd8310b065",
     "grade": true,
     "grade_id": "cell-c19776c62148ed3f",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# Report results here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "305ac6686c2cac2f4c01d5249297b590",
     "grade": true,
     "grade_id": "cell-daca4a565756ec40",
     "locked": false,
     "points": 2.5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Make plots here\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "98793a6d4b7ccb17efac41169da3c6fe",
     "grade": false,
     "grade_id": "cell-706704b71b1e28ac",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Part 3 [10 points]\n",
    "In the following space below discuss at least one advantage and disadvantage for *Random Forest* and *AdaBoost*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "2593940b46e846297e4ec5f1bec3e768",
     "grade": true,
     "grade_id": "cell-15ec51992550c8fc",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Optional survey.\n",
    "***\n",
    "\n",
    "We are always interested in your feedback. At the end of each homework, there is a simple anonymous feedback [survey](https://docs.google.com/forms/d/e/1FAIpQLSc_Sc1pp9MpiY5oVKayF0Cz1cnfmTbYe-8DZiKEdhsxSxyTaA/viewform?usp=pp_url) to solicit your feedback for how to improve the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "349.19px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
